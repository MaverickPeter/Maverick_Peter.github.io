---
layout:     post
title:      "基于大模型的问答系统"
subtitle:   " \"Large Model-based Question Answering Systems\""
date:       2024-01-05 19:00:00
author:     "xxc"
header-img: "img/black_bg.jpg"
catalog: true
tags:
    - 知识分享
    - 日常学习

---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>


### 问答系统基本结构：
![](/img/LLM-QA-system/1.png)

### 大模型带来的价值：
+ 通识知识
+ 推理能力
+ 多模态数据处理

![](/img/LLM-QA-system/2.png)

### 大模型的局限：
+ 垂直领域知识没有，知识更新慢
+ 没有小模型的专业能力
+ 幻觉

![](/img/LLM-QA-system/3.png)

### RAG技术方案 - Embedding召回：
+ embedding 召回内容块
+ LLM功能：
    - 意图识别
    - 推理，总结

![](/img/LLM-QA-system/4.png)

#### embedding 好处：
+ 将维度降低
+ 可以体现部分语义关系
+ 多模态数据可以统一表征

![](/img/LLM-QA-system/5.png)

#### embedding 局限：
##### 一些问题
    1. **召回精度低** -> 有效信息密度低
    2. **粒度过粗** -> token浪费，影响LLM处理速度和精度
    3. **不能替代信息提取** -> 实体/关系/事件，条件/统计查询，外部工具链使用（推荐服务），不适合任务式对话（调用API并补全参数）
    4. **上下文支持有限 **-> 分片粒度选择，如何避免信息丢失，如何召回上下文
    5. excel 数据很难处理和推理（设计提问补全？）

##### 可能的解决方案：
    1. LLM生成虚拟文档，扩充问题，再用于embedding召回
        1. 会增加时间和调用开销
        2. LLM需要微调，做垂类
    2. LLM实现信息提取：识别实体类型，基于类型提取实体
        1. 效果一般
        2. 缺少意图识别
        3. 精度不高
        4. 时间开销大

![](/img/LLM-QA-system/6.png)

![](/img/LLM-QA-system/7.png)

![](/img/LLM-QA-system/8.png)

![](/img/LLM-QA-system/9.png)

![](/img/LLM-QA-system/10.png)

![](/img/LLM-QA-system/11.png)

![](/img/LLM-QA-system/12.png)

![](/img/LLM-QA-system/13.png)

### RAG技术方案优化 - 意图识别优化：
#### 传统方案 - 基于词性标注和句法分析
1. 传统NLP技术可以实现并列，从属等关系，实现问题补全扩充
    - 没有意图并不能帮助理解用户问题

#### 传统方案 - 意图分类+命名实体识别
1. 单轮对话
    1. 意图分类（BERT/DIET），提供槽位
    2. 命名实体识别（BERT/DIET），填充槽位
    3. 指代消解与省略语补全（LSTM/ELMo/BERT）分类问题
    4. BERT
        1. BERT提供CLS头部分类标记，需要与业务对接进行finetune，实现具体分类
        2. BERT对此进行mask，实现实体实体
        3. BERT同时实现意图预测和命名实体识别，联合训练
        4. 训练开销大
    5. DIET（rasa）
        1. 根据用户数据迭代
        2. 数据集准备
            1. 专业名词替换
2. 复杂任务的多轮对话
    1. 根据意图，把缺失信息提问
    2. 分类式响应：预定义一些问题
    3. 生成式响应：通过相似性排序

![](/img/LLM-QA-system/14.png)

![](/img/LLM-QA-system/15.png)

![](/img/LLM-QA-system/16.png)

![](/img/LLM-QA-system/17.png)

![](/img/LLM-QA-system/18.png)

![](/img/LLM-QA-system/19.png)

![](/img/LLM-QA-system/20.png)

![](/img/LLM-QA-system/21.png)

![](/img/LLM-QA-system/22.png)

![](/img/LLM-QA-system/23.png)

![](/img/LLM-QA-system/24.png)

![](/img/LLM-QA-system/25.png)

![](/img/LLM-QA-system/26.png)

![](/img/LLM-QA-system/27.png)
![](/img/LLM-QA-system/28.png)

![](/img/LLM-QA-system/29.png)

![](/img/LLM-QA-system/30.png)
![](/img/LLM-QA-system/31.png)

![](/img/LLM-QA-system/32.png)


![](/img/LLM-QA-system/33.png)



### RAG技术方案优化 - 检索优化：
#### 知识库
1. 向量库
    1. 普通文本
    2. pdf
    3. doc
2. 关系数据库
    1. 表格类数据
3. 图数据库
    1. 非结构化数据

#### 普通文本检索优化
1. 文档预处理
    1. 采集/清洗/转为html
    2. 分片，分层级
2. 分片和入库
    1. 给出chunk id  等等用于其他算法
3. 召回

#### 结构化数据检索
1. 数据格式转为 panda dataframe / SQL
    1. 理解用户问题，生成code，去跑工具
    2. Prompt：CoT
    3. 依赖LLM性能，要做降级处理
2. Text2SQL
    1. 获取数据表
    2. 生成Prompt
    3. 结果提取
    4. 业务层校验
    5. 成功率比较低 < 40%（SFT结果不一定好）
3. 基于规则生成 SQL，pandas
    1. 看业务，场景少可以用
    2. 枚举

#### 图数据检索
1. 适合的应用场景
    1. 适合稀疏和复杂关系（多步关系）数据
2. 做推荐

![](/img/LLM-QA-system/34.png)

![](/img/LLM-QA-system/35.png)

![](/img/LLM-QA-system/36.png)

![](/img/LLM-QA-system/37.png)

![](/img/LLM-QA-system/38.png)

![](/img/LLM-QA-system/39.png)

![](/img/LLM-QA-system/40.png)

![](/img/LLM-QA-system/41.png)

![](/img/LLM-QA-system/42.png)



### RAG技术方案优化 - 降级处理：
![](/img/LLM-QA-system/43.png)



![](/img/LLM-QA-system/44.png)

### RAG技术方案优化 - Agent（以业务为中心）：
#### 需求驱动
    1. 业务为中心，开发组件，LLM也是一个组件
    2. LLM主攻NLG和推理
    3. 垂类语料建设

![](/img/LLM-QA-system/45.png)

![](/img/LLM-QA-system/46.png)

